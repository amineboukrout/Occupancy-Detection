{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occupancy detection using K-NN\n",
    "\n",
    "In this practical session, we will design and implement supervised learning method(s) for occupancy detection of an office room. The dataset we will use is from [Luis M. Candanedo, Veronique Feldheim, \"Accurate occupancy\n",
    "detection of an office room from light, temperature, humidity and CO2 measurements using statistical learning models\", Energy and Buildings, Volume 112, 15 January 2016, Pages 28-39](https://doi.org/10.1016/j.enbuild.2015.11.071)\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset has a training set of 8143 examples and a test set of 2665 examples. Each example is comprised of features (acquired through sensors from an office room) and the corresponding target value (**Occupancy**). The features (**Temperature**, **Humidty**, **Light**, **CO2**, **Humidity_Ratio**) recorded for each example to predict the state of the office room (**Occupancy**).\n",
    "\n",
    "## Loading data\n",
    "\n",
    "The following code segment loads both training and testing data from text files `../data/trainingdata.txt` and `../data/testingdata.txt`, respectively. Each row of 2D NumPy arrays `training_data` and `testing_data` respectively refers to an example from the training and testing datasets. The last column of each row refers to the target value, either 0 or 1 respectively representing **Unoccupied** or **Occupied** room.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "# training data\n",
    "training_data = np.loadtxt('../data/trainingdata.txt', usecols=(2,3,4,5,6,7), skiprows=1, delimiter=',')\n",
    "x_training = training_data[:, :-1]\n",
    "y_training = training_data[:, -1]\n",
    "print('number of samples in training data = ' + np.str(y_training.shape[0]))\n",
    "\n",
    "# testing data\n",
    "testing_data = np.loadtxt('../data/testingdata.txt', usecols=(2,3,4,5,6,7), skiprows=1, delimiter=',')\n",
    "x_testing = testing_data[:, :-1]\n",
    "y_testing = testing_data[:, -1]\n",
    "print('number of samples in testing data = ' + np.str(y_testing.shape[0]))\n",
    "\n",
    "# feature names and their indexes on the 2D NumPy array\n",
    "feature_index_names = {0:'Temperature', 1:'Humidity', 2:'Light', 3:'CO2', 4:'Humidity_Ratio'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "### Scatter plot\n",
    "\n",
    "Scatter plotting is a great tool in order to identify _discriminative_ features. The following function performs scatter plotting of pairwise features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_plot(x, y, feature_index_names):\n",
    "    c = ['r', 'b']\n",
    "    m = ['s', 'o']\n",
    "    s = [32, 32]\n",
    "    l = [r'$0$', r'$1$'] \n",
    "    font_size = 22\n",
    "    x_class0 = x[y==0.0, :]\n",
    "    x_class1 = x[y==1.0, :]    \n",
    "    for i in np.arange(len(feature_index_names)-1):\n",
    "        for j in np.arange(i+1, len(feature_index_names)):\n",
    "            figure_name = feature_index_names[i] + ' vs ' + feature_index_names[j]\n",
    "            pl.figure(figure_name)\n",
    "            pl.scatter(x_class0[:, i], x_class0[:, j], c=c[0], marker=m[0], s=s[0], label=l[0])\n",
    "            pl.scatter(x_class1[:, i], x_class1[:, j], c=c[1], marker=m[1], s=s[1], label=l[1])\n",
    "            pl.xlabel(feature_index_names[i], fontsize=font_size)\n",
    "            pl.ylabel(feature_index_names[j], fontsize=font_size)\n",
    "            pl.legend(scatterpoints=1, fontsize=font_size, loc = 'upper right')\n",
    "            pl.title(figure_name, fontsize=font_size)\n",
    "            pl.tight_layout()\n",
    "            pl.savefig(figure_name + '.jpg')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following code segment to perform scatter plot of all pairwise features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter_plot(x_training, y_training, feature_index_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sample correlation coeffient\n",
    "\n",
    "Based on the scatter plots, it may be a good idea to choose **Light** and **CO2** as our discriminative features to predict the state of the office room. But, can we somehow quantify this? How about using _sample correlation coefficient_ between features and target varget values? Let $x_{i}^{(n)}$ denote $i$th feature of example $n$, and $y^{(n)}$ denote the corresponding target value. The _sample correlation coefficient_ between $x_{i}$ and $y$ is defined as follows\n",
    "$$\n",
    "r\\left(x_{i}, y\\right) = \\frac{\\sum\\limits_{n=1}^{N} \\left(x_{i}^{(n)} - \\hat{x}_{i}\\right) \\left(y^{(n)} - \\hat{y}\\right)}{\\sqrt{\\sum\\limits_{n=1}^{N} \\left(x_{i}^{(n)} - \\hat{x}_{i}\\right)^{2} \\sum\\limits_{n=1}^{N} \\left(y^{(n)} - \\hat{y}\\right)^{2}}},\n",
    "$$\n",
    "where $\\hat{x}_{i} = \\frac{1}{N}\\sum\\limits_{n=1}^{N}x_{i}^{(n)}$ is the sample mean of $x_{i}$, and analogously for $\\hat{y}$. \n",
    "\n",
    "The following function `corr_coef` and code segment computes and displays the sample correlation coeffients between features and target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr_coef(x, y):\n",
    "    x_m = (x - np.mean(x))\n",
    "    y_m = (y - np.mean(y))\n",
    "    r = np.sum(x_m * y_m) / np.sqrt(np.sum(x_m**2) * np.sum(y_m**2))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = y_training.copy()\n",
    "for i in np.arange(len(feature_index_names)):\n",
    "    x_i = x_training[:, i]\n",
    "    r = corr_coef(x_i, y)    \n",
    "    print('r(' + feature_index_names[i] + ', Occupancy) = ' + '{:.4f}'.format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe from the sample correlation coefficients between features and target values, **Light** and **CO2** are highly correlated to the state of the office room. Did you expect this? Based on the sample correlation, can you find out which features are highly correlated? Modify the following code segment to compute the sample correlation coefficient between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in np.arange(len(feature_index_names)-1):\n",
    "    for j in np.arange(i+1, len(feature_index_names)):\n",
    "        #x_i = x_training[:, i]\n",
    "        #x_j = x_training[:, j]\n",
    "        #r = corr_coef(x_i, x_j)\n",
    "        '''\n",
    "        Modify the code segment here to compute the sample correlation coefficient between features.\n",
    "        '''\n",
    "        r = 1.0\n",
    "        print('r(' + feature_index_names[i] + ', ' + feature_index_names[j] + ') = ' + '{:.4f}'.format(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column indexes of **Light** and **CO2** in `x_training` and `x_testing` arrays are 2 and 3, respectively. The following code segment creates a copy of training and testing datasets comprised of only features **Light** and **CO2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_training_selected = x_training[:,[2, 3]]\n",
    "x_testing_selected = x_testing[:,[2, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding and plotting K-Nearest Neighbours of the query  point\n",
    "\n",
    "Assume that we have a sample measurement (or query point, or test point) from the office room \n",
    " $\\mathbf{x}^{\\left(q\\right)} = \\left[\\begin{array}{c} x_{1}^{\\left(q\\right)} \\\\ x_{2}^{\\left(q\\right)}\\end{array}\\right] = \\left[\\begin{array}{l} \\text{Light} \\\\ \\text{CO}_{2}\\end{array}\\right] = \\left[\\begin{array}{l} 200.0000 \\\\ 1000.0000 \\end{array}\\right]$, and we want to predict if the room is occupied or unoccupied. If the number of features is less than or equal to 3, then we can either use 2D or 3D scatter plot to observe the proximity of the query point to the examples in our training dataset to make prediction about the room status. The following function and code segment do the scatter plot and shows K-Nearest Neighbours of the query point from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scatter_plot_two_features_only(x, y, feature1_name, feature2_name, x_q, K=3):\n",
    "    c = ['r', 'b', 'g']\n",
    "    m = ['s', 'o', '*']\n",
    "    s = [32, 32, 64]\n",
    "    l = [r'$0$', r'$1$', r'query']\n",
    "    font_size = 22\n",
    "    x_class0 = x[y==0.0, :]\n",
    "    x_class1 = x[y==1.0, :]    \n",
    "    figure_name = feature1_name + ' vs ' + feature2_name + ' Query'\n",
    "    pl.figure(figure_name)\n",
    "    pl.scatter(x_class0[:, 0], x_class0[:, 1], c=c[0], marker=m[0], s=s[0], label=l[0])\n",
    "    pl.scatter(x_class1[:, 0], x_class1[:, 1], c=c[1], marker=m[1], s=s[1], label=l[1])\n",
    "    pl.scatter(x_q[0], x_q[1], c=c[2], marker=m[2], s=s[2], label=l[2])\n",
    "    # find the nearest neighbours\n",
    "    d = np.sqrt(np.sum((x - x_q)**2, axis=1)) # use the Euclidean distance\n",
    "    i = np.argsort(d)\n",
    "    for k in np.arange(K):\n",
    "        temp = np.vstack((x_q, x[i[k],:]))\n",
    "        pl.plot(temp[:,0], temp[:,1], c = c[2], linewidth=2)    \n",
    "    pl.xlabel(feature1_name, fontsize=font_size)\n",
    "    pl.ylabel(feature2_name, fontsize=font_size)\n",
    "    pl.legend(scatterpoints=1, fontsize=font_size, loc = 'upper right')\n",
    "    pl.title(figure_name, fontsize=font_size)\n",
    "    pl.tight_layout()\n",
    "    pl.savefig(figure_name + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_q = np.array([200.0, 1000.0])\n",
    "x_q.shape\n",
    "scatter_plot_two_features_only(x_training_selected, y_training, feature_index_names[2], feature_index_names[3], x_q, 111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the prediction for the query point $\\mathbf{x}^{\\left(q\\right)} = \\left[\\begin{array}{c} x_{1}^{\\left(q\\right)} \\\\ x_{2}^{\\left(q\\right)}\\end{array}\\right] = \\left[\\begin{array}{l} \\text{Light} \\\\ \\text{CO}_{2}\\end{array}\\right] = \\left[\\begin{array}{l} 200.0000 \\\\ 1000.0000 \\end{array}\\right]$ when $K=111$? In order to make prediction for $K=111$, you can use the following function and code segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN(x, y, x_q, K=3):\n",
    "    target_labels = np.unique(y) # unique set of target labels\n",
    "    target_labels_counts = np.zeros(len(target_labels)) # keeps counts of target labels\n",
    "    d = np.sqrt(np.sum((x - x_q)**2, axis=1)) # use the Euclidean distance\n",
    "    i = np.argsort(d) # sort distance vector in ascending order\n",
    "    for k in np.arange(len(target_labels)):\n",
    "        target_labels_counts[k] = np.sum(y[i[0:K]]==target_labels[k]) # count the number of each target lable in K Nearest Neighbourhood\n",
    "    # apply the majority voting\n",
    "    l = np.argmax(target_labels_counts)\n",
    "    return target_labels[l]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_label = KNN(x_training_selected, y_training, x_q, K=111)\n",
    "print('prediction = ' + '{:.0f}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training error for different values of K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code segment computes training error for different values of $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = y_training.shape[0] # the number of examples in training dataset\n",
    "print('{:>2} {:>16}'.format('K', 'Training Error'))\n",
    "for K in np.arange(1, 34, 2):\n",
    "    y_prediction = np.zeros(N)\n",
    "    for n in np.arange(N):\n",
    "        x_q = x_training_selected[n]\n",
    "        y_prediction[n] = KNN(x_training_selected, y_training, x_q, K)\n",
    "    classification_error = np.sum(y_training != y_prediction) / N\n",
    "    print('{:>2.0f} {:>16.4f}'.format(K, classification_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you compute testing error of the classifier for $K = 111$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
